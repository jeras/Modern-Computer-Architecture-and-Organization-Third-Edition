__Modern Computer Architecture and Organization Third Edition__, by Jim Ledin. Published by Packt Publishing.
# Chapter 8: Performance-Enhancing Techniques

The fundamental capabilities of processor and memory architectures discussed in previous chapters enable the design of a complete and functional computer system. However, without additional features to enhance instruction execution speed, the performance of such a system would be inferior to that of most modern processors.

Several performance-enhancing techniques are employed routinely in processor and system designs to achieve peak execution speed in real-world computer systems. These techniques do not alter the processor’s behavior in terms of code execution and data processing; they simply enable the system to complete tasks faster.

After completing this chapter, you will understand the benefits of multilevel cache memory in computer architectures and the advantages and challenges associated with instruction pipelining. You’ll also understand the performance improvement resulting from simultaneous multithreading and the purpose and applications of single-instruction, multiple-data processing.

The following topics will be covered in this chapter:

* Cache memory
* Instruction pipelining
* Simultaneous multithreading
* SIMD processing

# Answers to Exercises
The links below lead to the questions and answers for the end-of-chapter exercises.

[Exercise 1](Answers%20to%20Exercises/Ex__1_direct_mapped_cache.md): Compute the cache tag size and tag bit positions for a direct-mapped L1 instruction cache.

[Exercise 2](Answers%20to%20Exercises/Ex__2_8_way_cache.md): Determine the number of sets in an 8-way set-associative L2 cache.

[Exercise 3](Answers%20to%20Exercises/Ex__3_add_pipeline_stage.md): Calculate the percentage increase in clock speed after splitting a pipeline stage.
